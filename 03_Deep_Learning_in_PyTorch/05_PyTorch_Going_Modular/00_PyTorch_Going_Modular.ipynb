{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Going Modular\n",
        "\n",
        "### [Resource](https://www.learnpytorch.io/05_pytorch_going_modular/)\n",
        "\n",
        "Turning the most useful code cells in [`00_PyTorch_Custom_Datasets`](https://github.com/LuluW8071/Data-Science/tree/main/Pytorch/04_PyTorch_Custom_Datasets) into a series of Python scripts saved to a directory called going_modular.\n",
        "\n",
        "### What is going modular?\n",
        "Going modular involves turning notebook code (from a **Jupyter Notebook** or **Google Colab Notebook**) into a series of different Python scripts that offer similar functionality.\n",
        "\n",
        "For example, we could turn our notebook code from a series of cells into the following Python files:\n",
        "\n",
        "- `data_setup.py` - a file to prepare and download data if needed.\n",
        "- `dataset.py` - a file to create a dataloader.\n",
        "- `model_builder.py` or `model.py` - a file to create a PyTorch model.\n",
        "- `engine.py` - a file containing various training functions.\n",
        "- `train.py` - a file to leverage all other files and train a target PyTorch model.\n",
        "- `utils.py` - a file dedicated to helpful utility functions.\n",
        "\n",
        "### Why would you want to go **modular**?\n",
        "Notebooks are fantastic for iteratively exploring and running experiments quickly. However, for larger scale projects you may find Python scripts more reproducible and easier to run.\n",
        "\n",
        "For example, if you have an app running online that other people can access and use, the code running that app is considered **production code**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pros and Cons of Notebooks vs Scripts\n",
        "\n",
        "|                | Pros                                                  | Cons                                                                  |\n",
        "|----------------|-------------------------------------------------------|-----------------------------------------------------------------------|\n",
        "| Notebooks      | Easy to experiment/get started                        | Versioning can be hard                                                |\n",
        "|                | Easy to share (e.g. a link to a Google Colab notebook)| Hard to use only specific parts                                       |\n",
        "|                | Very visual                                           | Text and graphics can get in the way of code                          |\n",
        "\n",
        "\n",
        "|                | **Pros**                                              | **Cons**                                                              |\n",
        "|----------------|-------------------------------------------------------|-----------------------------------------------------------------------|\n",
        "| Python scripts | Can package code together (saves rewriting similar code across different notebooks) | Experimenting isn't as visual (usually have to run the whole script rather than one cell) |\n",
        "|                | Can use git for versioning                                                        |                                         |\n",
        "|                | Many open source projects use scripts                                             |                                         |\n",
        "|                | Larger projects can be run on cloud vendors (not as much support for notebooks)   |                                         |\n",
        "\n",
        "## What we're working towards\n",
        "By the end of this section we want to have two things:\n",
        "\n",
        "1. The ability to train the model we built in [`04_PyTorch_Custom_Datasets`](https://github.com/LuluW8071/Data-Science/tree/main/Pytorch/04_PyTorch_Custom_Datasets) with one line of code on the command line:\n",
        "\n",
        "    ```bash\n",
        "    python train.py\n",
        "    ```\n",
        "\n",
        "2. A directory structure of reusable Python scripts, such as:\n",
        "\n",
        "    ```\n",
        "    05_PyTorch_Going_Modular/\n",
        "    ├── going_modular/\n",
        "    |   ├── data_setup.py\n",
        "    |   ├── dataset.py\n",
        "    |   ├── engine.py\n",
        "    |   ├── model.py\n",
        "    |   ├── train.py\n",
        "    |   ├── utils.py\n",
        "    |   └── dataset/\n",
        "    |       ├── test/\n",
        "    |       │   ├── donuts\n",
        "    |       │   ├── dumplings\n",
        "    |       │   ├── ice_cream\n",
        "    |       │   ├── pizza\n",
        "    |       │   ├── ramen\n",
        "    |       │   ├── samosa\n",
        "    |       │   ├── steak\n",
        "    |       │   └── sushi\n",
        "    |       └── train/\n",
        "    |           ├── donuts\n",
        "    |           ├── dumplings\n",
        "    |           ├── ice_cream\n",
        "    |           ├── pizza\n",
        "    |           ├── ramen\n",
        "    |           ├── samosa\n",
        "    |           ├── steak\n",
        "    |           └── sushi\n",
        "    └── models/\n",
        "        └── tinyvgg_model.pth\n",
        "    ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After writing the scripts, run the command in terminal:\n",
        "\n",
        "```bash\n",
        "python train.py\n",
        "```\n",
        "\n",
        "<i>**Note**: \n",
        "If you dont have external GPU you can also\n",
        "- use colab notebook,\n",
        "- Just Upload scripts on colab runtime, and \n",
        "- Don't forget to switch runtime to T4GPU</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDzhqcKCblel",
        "outputId": "e3d88492-fad5-4555-83ab-e1a7cf55d4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1J0syU84FNmtxkf9AzDPdRSDmtUr1CSy8\n",
            "From (redirected): https://drive.google.com/uc?id=1J0syU84FNmtxkf9AzDPdRSDmtUr1CSy8&confirm=t&uuid=0e0cfab4-0c19-4381-b70d-1aa293fb1387\n",
            "To: /content/Food_dataset.zip\n",
            "100% 367M/367M [00:04<00:00, 87.4MB/s]\n",
            "Files extracted successfully to: ./dataset\n",
            "  0% 0/100 [00:00<?, ?it/s]\n",
            "Epoch: 1 | Train loss: 2.0327 - Train acc: 19.99% -- Test_loss: 1.9544 -- Test_acc: 23.89%\n",
            "  1% 1/100 [00:34<56:20, 34.14s/it]\n",
            "Epoch: 2 | Train loss: 1.9358 - Train acc: 26.23% -- Test_loss: 1.8934 -- Test_acc: 26.29%\n",
            "  2% 2/100 [01:07<55:20, 33.88s/it]\n",
            "Epoch: 3 | Train loss: 1.8911 - Train acc: 27.52% -- Test_loss: 1.9725 -- Test_acc: 22.76%\n",
            "  3% 3/100 [01:41<54:56, 33.98s/it]\n",
            "Epoch: 4 | Train loss: 1.8232 - Train acc: 31.60% -- Test_loss: 1.7604 -- Test_acc: 34.98%\n",
            "  4% 4/100 [02:14<53:38, 33.53s/it]\n",
            "Epoch: 5 | Train loss: 1.7706 - Train acc: 35.18% -- Test_loss: 1.7971 -- Test_acc: 31.27%\n",
            "  5% 5/100 [02:48<53:04, 33.52s/it]\n",
            "Epoch: 6 | Train loss: 1.7377 - Train acc: 35.26% -- Test_loss: 1.7569 -- Test_acc: 33.71%\n",
            "  6% 6/100 [03:21<52:32, 33.54s/it]\n",
            "Epoch: 7 | Train loss: 1.6960 - Train acc: 38.63% -- Test_loss: 1.6941 -- Test_acc: 37.42%\n",
            "  7% 7/100 [03:54<51:41, 33.35s/it]\n",
            "Epoch: 8 | Train loss: 1.6610 - Train acc: 39.90% -- Test_loss: 1.6398 -- Test_acc: 40.12%\n",
            "  8% 8/100 [04:28<51:15, 33.43s/it]\n",
            "Epoch: 9 | Train loss: 1.6087 - Train acc: 41.56% -- Test_loss: 1.6065 -- Test_acc: 40.91%\n",
            "  9% 9/100 [05:02<50:55, 33.58s/it]\n",
            "Epoch: 10 | Train loss: 1.5893 - Train acc: 43.38% -- Test_loss: 1.5234 -- Test_acc: 45.50%\n",
            " 10% 10/100 [05:35<50:07, 33.42s/it]\n",
            "Epoch: 11 | Train loss: 1.5426 - Train acc: 44.91% -- Test_loss: 1.4595 -- Test_acc: 46.98%\n",
            " 11% 11/100 [06:09<49:51, 33.62s/it]\n",
            "Epoch: 12 | Train loss: 1.5142 - Train acc: 45.59% -- Test_loss: 1.4664 -- Test_acc: 45.81%\n",
            " 12% 12/100 [06:43<49:21, 33.66s/it]\n",
            "Epoch: 13 | Train loss: 1.4746 - Train acc: 47.93% -- Test_loss: 1.4165 -- Test_acc: 49.98%\n",
            " 13% 13/100 [07:15<48:19, 33.33s/it]\n",
            "Epoch: 14 | Train loss: 1.4460 - Train acc: 48.58% -- Test_loss: 1.4859 -- Test_acc: 46.89%\n",
            " 14% 14/100 [07:49<48:02, 33.51s/it]\n",
            "Epoch: 15 | Train loss: 1.4208 - Train acc: 50.08% -- Test_loss: 1.3500 -- Test_acc: 51.86%\n",
            " 15% 15/100 [08:23<47:37, 33.61s/it]\n",
            "Epoch: 16 | Train loss: 1.3945 - Train acc: 51.14% -- Test_loss: 1.3046 -- Test_acc: 53.71%\n",
            " 16% 16/100 [08:56<46:56, 33.53s/it]\n",
            "Epoch: 17 | Train loss: 1.3650 - Train acc: 51.56% -- Test_loss: 1.3686 -- Test_acc: 52.48%\n",
            " 17% 17/100 [09:31<46:39, 33.73s/it]\n",
            "Epoch: 18 | Train loss: 1.3248 - Train acc: 53.45% -- Test_loss: 1.3164 -- Test_acc: 54.76%\n",
            " 18% 18/100 [10:05<46:32, 34.06s/it]\n",
            "Epoch: 19 | Train loss: 1.3136 - Train acc: 53.26% -- Test_loss: 1.3041 -- Test_acc: 53.08%\n",
            " 19% 19/100 [10:39<45:35, 33.77s/it]\n",
            "Epoch: 20 | Train loss: 1.2699 - Train acc: 54.96% -- Test_loss: 1.3700 -- Test_acc: 52.47%\n",
            " 20% 20/100 [11:13<45:11, 33.89s/it]\n",
            "Epoch: 21 | Train loss: 1.2966 - Train acc: 54.14% -- Test_loss: 1.2309 -- Test_acc: 56.17%\n",
            " 21% 21/100 [11:47<44:45, 34.00s/it]\n",
            "Epoch: 22 | Train loss: 1.2430 - Train acc: 56.85% -- Test_loss: 1.2252 -- Test_acc: 56.63%\n",
            " 22% 22/100 [12:20<43:48, 33.70s/it]\n",
            "Epoch: 23 | Train loss: 1.2262 - Train acc: 57.27% -- Test_loss: 1.2428 -- Test_acc: 56.83%\n",
            " 23% 23/100 [12:54<43:12, 33.67s/it]\n",
            "Epoch: 24 | Train loss: 1.2209 - Train acc: 58.04% -- Test_loss: 1.2742 -- Test_acc: 54.31%\n",
            " 24% 24/100 [13:28<42:50, 33.82s/it]\n",
            "Epoch: 25 | Train loss: 1.1751 - Train acc: 59.25% -- Test_loss: 1.1196 -- Test_acc: 61.43%\n",
            " 25% 25/100 [14:01<42:02, 33.64s/it]\n",
            "Epoch: 26 | Train loss: 1.1550 - Train acc: 59.84% -- Test_loss: 1.2708 -- Test_acc: 55.26%\n",
            " 26% 26/100 [14:34<41:23, 33.57s/it]\n",
            "Epoch: 27 | Train loss: 1.1446 - Train acc: 60.06% -- Test_loss: 1.1509 -- Test_acc: 61.09%\n",
            " 27% 27/100 [15:08<40:54, 33.63s/it]\n",
            "Epoch: 28 | Train loss: 1.1046 - Train acc: 62.68% -- Test_loss: 1.4259 -- Test_acc: 54.33%\n",
            " 28% 28/100 [15:41<40:00, 33.34s/it]\n",
            "Epoch: 29 | Train loss: 1.1002 - Train acc: 62.40% -- Test_loss: 1.1040 -- Test_acc: 61.50%\n",
            " 29% 29/100 [16:15<39:46, 33.61s/it]\n",
            "Epoch: 30 | Train loss: 1.0625 - Train acc: 63.47% -- Test_loss: 1.1191 -- Test_acc: 61.48%\n",
            " 30% 30/100 [16:50<39:32, 33.89s/it]\n",
            "Epoch: 31 | Train loss: 1.0479 - Train acc: 63.44% -- Test_loss: 1.0881 -- Test_acc: 61.83%\n",
            " 31% 31/100 [17:23<38:50, 33.77s/it]\n",
            "Epoch: 32 | Train loss: 1.0241 - Train acc: 65.05% -- Test_loss: 1.0685 -- Test_acc: 62.90%\n",
            " 32% 32/100 [17:57<38:11, 33.70s/it]\n",
            "Epoch: 33 | Train loss: 0.9977 - Train acc: 65.52% -- Test_loss: 1.2242 -- Test_acc: 58.32%\n",
            " 33% 33/100 [18:31<37:45, 33.82s/it]\n",
            "Epoch: 34 | Train loss: 0.9881 - Train acc: 66.10% -- Test_loss: 1.1185 -- Test_acc: 62.09%\n",
            " 34% 34/100 [19:03<36:48, 33.46s/it]\n",
            "Epoch: 35 | Train loss: 1.0013 - Train acc: 65.56% -- Test_loss: 1.0371 -- Test_acc: 65.99%\n",
            " 35% 35/100 [19:37<36:26, 33.64s/it]\n",
            "Epoch: 36 | Train loss: 0.9387 - Train acc: 67.94% -- Test_loss: 1.0249 -- Test_acc: 64.23%\n",
            " 36% 36/100 [20:11<36:00, 33.76s/it]\n",
            "Epoch: 37 | Train loss: 0.9186 - Train acc: 69.47% -- Test_loss: 1.0053 -- Test_acc: 65.89%\n",
            " 37% 37/100 [20:45<35:18, 33.63s/it]\n",
            "Epoch: 38 | Train loss: 0.9180 - Train acc: 68.87% -- Test_loss: 0.9493 -- Test_acc: 68.64%\n",
            " 38% 38/100 [21:18<34:39, 33.55s/it]\n",
            "Epoch: 39 | Train loss: 0.9125 - Train acc: 69.24% -- Test_loss: 1.0720 -- Test_acc: 65.79%\n",
            " 39% 39/100 [21:52<34:07, 33.57s/it]\n",
            "Epoch: 40 | Train loss: 0.8816 - Train acc: 69.74% -- Test_loss: 1.1476 -- Test_acc: 62.41%\n",
            " 40% 40/100 [22:25<33:21, 33.36s/it]\n",
            "Epoch: 41 | Train loss: 0.8479 - Train acc: 71.83% -- Test_loss: 1.0638 -- Test_acc: 63.96%\n",
            " 41% 41/100 [22:58<32:43, 33.28s/it]\n",
            "Epoch: 42 | Train loss: 0.8577 - Train acc: 71.19% -- Test_loss: 1.0074 -- Test_acc: 67.39%\n",
            " 42% 42/100 [23:32<32:23, 33.50s/it]\n",
            "Epoch: 43 | Train loss: 0.8525 - Train acc: 71.29% -- Test_loss: 1.0786 -- Test_acc: 64.76%\n",
            " 43% 43/100 [24:05<31:39, 33.32s/it]\n",
            "Epoch: 44 | Train loss: 0.7993 - Train acc: 72.63% -- Test_loss: 1.2611 -- Test_acc: 60.79%\n",
            " 44% 44/100 [24:38<31:13, 33.45s/it]\n",
            "Epoch: 45 | Train loss: 0.7860 - Train acc: 73.53% -- Test_loss: 1.0070 -- Test_acc: 66.36%\n",
            " 45% 45/100 [25:12<30:48, 33.61s/it]\n",
            "Epoch: 46 | Train loss: 0.7634 - Train acc: 74.17% -- Test_loss: 0.9633 -- Test_acc: 68.99%\n",
            " 46% 46/100 [25:46<30:11, 33.54s/it]\n",
            "Epoch: 47 | Train loss: 0.7314 - Train acc: 75.61% -- Test_loss: 1.0438 -- Test_acc: 66.16%\n",
            " 47% 47/100 [26:20<29:43, 33.65s/it]\n",
            "Epoch: 48 | Train loss: 0.7648 - Train acc: 74.72% -- Test_loss: 1.0151 -- Test_acc: 68.23%\n",
            " 48% 48/100 [26:54<29:18, 33.81s/it]\n",
            "Epoch: 49 | Train loss: 0.7387 - Train acc: 75.05% -- Test_loss: 1.0066 -- Test_acc: 67.19%\n",
            " 49% 49/100 [27:27<28:31, 33.55s/it]\n",
            "Epoch: 50 | Train loss: 0.7277 - Train acc: 75.48% -- Test_loss: 0.9890 -- Test_acc: 68.23%\n",
            " 50% 50/100 [28:01<28:04, 33.69s/it]\n",
            "Epoch: 51 | Train loss: 0.7079 - Train acc: 77.15% -- Test_loss: 0.9658 -- Test_acc: 70.70%\n",
            " 51% 51/100 [28:35<27:33, 33.75s/it]\n",
            "Epoch: 52 | Train loss: 0.6951 - Train acc: 77.34% -- Test_loss: 0.9586 -- Test_acc: 68.25%\n",
            " 52% 52/100 [29:08<27:00, 33.76s/it]\n",
            "Epoch: 53 | Train loss: 0.6668 - Train acc: 78.51% -- Test_loss: 0.9357 -- Test_acc: 70.37%\n",
            " 53% 53/100 [29:42<26:24, 33.72s/it]\n",
            "Epoch: 54 | Train loss: 0.6743 - Train acc: 77.61% -- Test_loss: 0.9622 -- Test_acc: 68.12%\n",
            " 54% 54/100 [30:16<25:57, 33.86s/it]\n",
            "Epoch: 55 | Train loss: 0.6708 - Train acc: 77.31% -- Test_loss: 0.9869 -- Test_acc: 68.68%\n",
            " 55% 55/100 [30:50<25:18, 33.75s/it]\n",
            "Epoch: 56 | Train loss: 0.6462 - Train acc: 78.71% -- Test_loss: 0.8989 -- Test_acc: 70.38%\n",
            " 56% 56/100 [31:23<24:38, 33.60s/it]\n",
            "Epoch: 57 | Train loss: 0.6367 - Train acc: 79.25% -- Test_loss: 1.0487 -- Test_acc: 67.51%\n",
            " 57% 57/100 [31:57<24:10, 33.74s/it]\n",
            "Epoch: 58 | Train loss: 0.6135 - Train acc: 80.29% -- Test_loss: 0.8496 -- Test_acc: 73.89%\n",
            " 58% 58/100 [32:31<23:43, 33.90s/it]\n",
            "Epoch: 59 | Train loss: 0.6344 - Train acc: 79.85% -- Test_loss: 0.9319 -- Test_acc: 68.89%\n",
            " 59% 59/100 [33:04<23:00, 33.67s/it]\n",
            "Epoch: 60 | Train loss: 0.6238 - Train acc: 79.75% -- Test_loss: 1.0205 -- Test_acc: 69.69%\n",
            " 60% 60/100 [33:38<22:31, 33.78s/it]\n",
            "Epoch: 61 | Train loss: 0.6049 - Train acc: 80.05% -- Test_loss: 0.9538 -- Test_acc: 70.50%\n",
            " 61% 61/100 [34:12<21:57, 33.78s/it]\n",
            "Epoch: 62 | Train loss: 0.5909 - Train acc: 80.84% -- Test_loss: 0.9349 -- Test_acc: 71.34%\n",
            " 62% 62/100 [34:46<21:19, 33.68s/it]\n",
            "Epoch: 63 | Train loss: 0.5708 - Train acc: 81.14% -- Test_loss: 0.9125 -- Test_acc: 70.77%\n",
            " 63% 63/100 [35:20<20:48, 33.74s/it]\n",
            "Epoch: 64 | Train loss: 0.5675 - Train acc: 81.69% -- Test_loss: 0.9265 -- Test_acc: 70.48%\n",
            " 64% 64/100 [35:53<20:16, 33.78s/it]\n",
            "Epoch: 65 | Train loss: 0.5685 - Train acc: 81.65% -- Test_loss: 1.1205 -- Test_acc: 66.76%\n",
            " 65% 65/100 [36:27<19:35, 33.59s/it]\n",
            "Epoch: 66 | Train loss: 0.5614 - Train acc: 82.12% -- Test_loss: 0.9390 -- Test_acc: 71.88%\n",
            " 66% 66/100 [37:01<19:06, 33.73s/it]\n",
            "Epoch: 67 | Train loss: 0.5487 - Train acc: 82.29% -- Test_loss: 0.9695 -- Test_acc: 72.02%\n",
            " 67% 67/100 [37:34<18:31, 33.68s/it]\n",
            "Epoch: 68 | Train loss: 0.5113 - Train acc: 83.62% -- Test_loss: 0.9015 -- Test_acc: 72.91%\n",
            " 68% 68/100 [38:08<17:55, 33.60s/it]\n",
            "Epoch: 69 | Train loss: 0.5252 - Train acc: 82.59% -- Test_loss: 0.9072 -- Test_acc: 72.04%\n",
            " 69% 69/100 [38:42<17:26, 33.76s/it]\n",
            "Epoch: 70 | Train loss: 0.5285 - Train acc: 82.69% -- Test_loss: 0.9754 -- Test_acc: 71.34%\n",
            " 70% 70/100 [39:16<16:55, 33.86s/it]\n",
            "Epoch: 71 | Train loss: 0.5100 - Train acc: 84.14% -- Test_loss: 0.9711 -- Test_acc: 71.91%\n",
            " 71% 71/100 [39:49<16:12, 33.55s/it]\n",
            "Epoch: 72 | Train loss: 0.5075 - Train acc: 83.69% -- Test_loss: 1.0332 -- Test_acc: 69.67%\n",
            " 72% 72/100 [40:23<15:42, 33.66s/it]\n",
            "Epoch: 73 | Train loss: 0.5217 - Train acc: 82.98% -- Test_loss: 0.9010 -- Test_acc: 72.30%\n",
            " 73% 73/100 [40:57<15:11, 33.77s/it]\n",
            "Epoch: 74 | Train loss: 0.5066 - Train acc: 83.35% -- Test_loss: 1.0427 -- Test_acc: 69.37%\n",
            " 74% 74/100 [41:29<14:30, 33.47s/it]\n",
            "Epoch: 75 | Train loss: 0.4903 - Train acc: 84.54% -- Test_loss: 0.8824 -- Test_acc: 72.51%\n",
            " 75% 75/100 [42:03<13:59, 33.59s/it]\n",
            "Epoch: 76 | Train loss: 0.5095 - Train acc: 83.21% -- Test_loss: 0.9536 -- Test_acc: 71.61%\n",
            " 76% 76/100 [42:38<13:31, 33.83s/it]\n",
            "Epoch: 77 | Train loss: 0.5035 - Train acc: 83.98% -- Test_loss: 0.8641 -- Test_acc: 71.74%\n",
            " 77% 77/100 [43:11<12:54, 33.67s/it]\n",
            "Epoch: 78 | Train loss: 0.4818 - Train acc: 84.55% -- Test_loss: 0.8436 -- Test_acc: 76.16%\n",
            " 78% 78/100 [43:45<12:20, 33.66s/it]\n",
            "Epoch: 79 | Train loss: 0.4598 - Train acc: 84.77% -- Test_loss: 0.8272 -- Test_acc: 74.27%\n",
            " 79% 79/100 [44:19<11:51, 33.87s/it]\n",
            "Epoch: 80 | Train loss: 0.4591 - Train acc: 84.97% -- Test_loss: 0.9416 -- Test_acc: 71.90%\n",
            " 80% 80/100 [44:52<11:14, 33.71s/it]\n",
            "Epoch: 81 | Train loss: 0.4391 - Train acc: 86.40% -- Test_loss: 0.8719 -- Test_acc: 74.38%\n",
            " 81% 81/100 [45:26<10:42, 33.80s/it]\n",
            "Epoch: 82 | Train loss: 0.4646 - Train acc: 84.98% -- Test_loss: 0.9683 -- Test_acc: 71.56%\n",
            " 82% 82/100 [46:00<10:09, 33.88s/it]\n",
            "Epoch: 83 | Train loss: 0.4492 - Train acc: 85.42% -- Test_loss: 0.8777 -- Test_acc: 72.36%\n",
            " 83% 83/100 [46:33<09:31, 33.63s/it]\n",
            "Epoch: 84 | Train loss: 0.4333 - Train acc: 86.03% -- Test_loss: 0.8777 -- Test_acc: 74.19%\n",
            " 84% 84/100 [47:07<08:58, 33.64s/it]\n",
            "Epoch: 85 | Train loss: 0.4615 - Train acc: 85.14% -- Test_loss: 0.9307 -- Test_acc: 73.54%\n",
            " 85% 85/100 [47:42<08:29, 33.96s/it]\n",
            "Epoch: 86 | Train loss: 0.4323 - Train acc: 85.89% -- Test_loss: 0.9298 -- Test_acc: 73.67%\n",
            " 86% 86/100 [48:16<07:54, 33.89s/it]\n",
            "Epoch: 87 | Train loss: 0.4351 - Train acc: 85.91% -- Test_loss: 1.0617 -- Test_acc: 69.76%\n",
            " 87% 87/100 [48:49<07:17, 33.65s/it]\n",
            "Epoch: 88 | Train loss: 0.4577 - Train acc: 85.49% -- Test_loss: 1.2113 -- Test_acc: 68.86%\n",
            " 88% 88/100 [49:23<06:44, 33.74s/it]\n",
            "Epoch: 89 | Train loss: 0.4188 - Train acc: 86.94% -- Test_loss: 0.9434 -- Test_acc: 72.95%\n",
            " 89% 89/100 [49:56<06:10, 33.71s/it]\n",
            "Epoch: 90 | Train loss: 0.4104 - Train acc: 87.03% -- Test_loss: 0.8478 -- Test_acc: 75.82%\n",
            " 90% 90/100 [50:30<05:36, 33.69s/it]\n",
            "Epoch: 91 | Train loss: 0.4021 - Train acc: 86.90% -- Test_loss: 0.9420 -- Test_acc: 73.44%\n",
            " 91% 91/100 [51:04<05:04, 33.80s/it]\n",
            "Epoch: 92 | Train loss: 0.4227 - Train acc: 86.74% -- Test_loss: 0.9135 -- Test_acc: 73.68%\n",
            " 92% 92/100 [51:37<04:29, 33.68s/it]\n",
            "Epoch: 93 | Train loss: 0.4070 - Train acc: 86.74% -- Test_loss: 0.9758 -- Test_acc: 72.53%\n",
            " 93% 93/100 [52:11<03:55, 33.59s/it]\n",
            "Epoch: 94 | Train loss: 0.3988 - Train acc: 87.43% -- Test_loss: 0.8669 -- Test_acc: 74.67%\n",
            " 94% 94/100 [52:45<03:22, 33.69s/it]\n",
            "Epoch: 95 | Train loss: 0.4226 - Train acc: 86.56% -- Test_loss: 0.9130 -- Test_acc: 73.93%\n",
            " 95% 95/100 [53:18<02:48, 33.69s/it]\n",
            "Epoch: 96 | Train loss: 0.4155 - Train acc: 86.78% -- Test_loss: 0.8987 -- Test_acc: 75.63%\n",
            " 96% 96/100 [53:52<02:14, 33.54s/it]\n",
            "Epoch: 97 | Train loss: 0.4051 - Train acc: 87.31% -- Test_loss: 0.8900 -- Test_acc: 74.98%\n",
            " 97% 97/100 [54:27<01:42, 34.09s/it]\n",
            "Epoch: 98 | Train loss: 0.3925 - Train acc: 87.57% -- Test_loss: 0.8980 -- Test_acc: 75.54%\n",
            " 98% 98/100 [55:02<01:08, 34.47s/it]\n",
            "Epoch: 99 | Train loss: 0.4013 - Train acc: 86.70% -- Test_loss: 0.9473 -- Test_acc: 72.15%\n",
            " 99% 99/100 [55:35<00:33, 33.91s/it]\n",
            "Epoch: 100 | Train loss: 0.4260 - Train acc: 86.51% -- Test_loss: 0.8928 -- Test_acc: 74.40%\n",
            "100% 100/100 [56:09<00:00, 33.70s/it]\n",
            "[INFO] Saving model to: models/tinyvgg_model.pth\n"
          ]
        }
      ],
      "source": [
        "!python3 train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run the demo version of `05_PyTorch_Going_Modular`, install the required dependencies from `demo` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd demo\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run streamlit command for local web deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "streamlit run main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The trained model seems to be underfitting which could be mainly due to \n",
        "- the model is too simple, So it may be not capable to represent the complexities in the data.\n",
        "- the input features which is used to train the model is not the adequate representations of underlying factors influencing the target variable.\n",
        "- the size of the training dataset used is not enough.\n",
        "\n",
        "Maybe using other architecture like `ResNet50`, `EfficientNetB0` and other could produce better results."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, Viewing, Stacking, Squeezing, Unsqueezing & Permute Tensors\n",
    "\n",
    "1. **Reshaping**: Reshapes an input tensor to a defined shape.\n",
    "2. **View**: Returns a view of the input tensor of certain shape but keep the same memory as original .\n",
    "3. **Stacking**: Combine multiple tenmsors on top of each other <a href='https://pytorch.org/docs/stable/generated/torch.vstack.html'>(TORCH.VSTACK)</a> or side by side <a href='https://pytorch.org/docs/stable/generated/torch.hstack.html'>(TORCH.HSTACK)</a>.\n",
    "4. **Squeeze**: Removes all `1` dimensions from a tensor.\n",
    "5. **Unsqueeze**: Add `1` dimension to a target tensor.\n",
    "6. **Permute**: Return a view of the input with dimensions permuted(swapped) in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 5]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Adding extra dimensions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x_reshaped, x_reshaped\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 5]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "# Adding extra dimensions\n",
    "x_reshaped = x.reshape(1, 5)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.reshape()` is only compatible when the torch size matches as:\n",
    "- `x = torch.arange(1.,10.)`</br>\n",
    "    `x, x.shape`\n",
    "    ```bash\n",
    "    (tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))\n",
    "    ```\n",
    "-   `torch.Size([9]) = torch.reshape(1, 9)`\n",
    "    \n",
    "    *1x9 = 9, 3x3 = 9*\n",
    "    \n",
    "-   `x_reshaped = x.reshape(1, 9)`\n",
    "    ```bash\n",
    "    (tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]),\n",
       " 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding extra dimensions\n",
    "x_reshaped = x.reshape(3, 3)\n",
    "y_reshaped = x.reshape(9, 1)\n",
    "\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]),\n",
       " 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped, y_reshaped.shape, y_reshaped.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z, changes x\n",
    "# this is because a view of a tensor shares the same memory as the original tensor\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack\n",
    "<a href='https://pytorch.org/docs/stable/generated/torch.stack.html'>TORCH.STACK Documentation</a>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenates a sequence of tensors along a new dimension.\n",
    "x = torch.stack([x, x, x, x], dim=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze\n",
    "<a href='https://pytorch.org/docs/stable/generated/torch.squeeze.html'>TORCH.SQUEEZE Documentation</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5099, 0.2453],\n",
      "         [0.1440, 0.2323]]]) torch.Size([1, 2, 2])\n",
      "tensor([[0.5099, 0.2453],\n",
      "        [0.1440, 0.2323]]) torch.Size([2, 2])\n",
      "tensor([[0.5099, 0.2453],\n",
      "        [0.1440, 0.2323]]) torch.Size([2, 2])\n",
      "tensor([[[0.5099, 0.2453],\n",
      "         [0.1440, 0.2323]]]) torch.Size([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,2,2)\n",
    "print(x, x.size())\n",
    "\n",
    "y = torch.squeeze(x)\n",
    "print(y, y.size())\n",
    "\n",
    "y = torch.squeeze(x, 0)\n",
    "print(y, y.size())\n",
    "\n",
    "y = torch.squeeze(x, 1)\n",
    "print(y, y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5099, 0.2453],\n",
       "         [0.1440, 0.2323]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x, (2, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeezing y_reshaped tensor\n",
    "y_reshaped, y_reshaped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() removes all single dimensions from a target tensor\n",
    "y_reshaped.squeeze(), y_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: \n",
      "tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Previous Shape: torch.Size([9, 1])\n",
      "------------------------------------------------------------\n",
      "New tensor: \n",
      "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New Shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(f'Previous tensor: \\n{y_reshaped}\\nPrevious Shape: {y_reshaped.shape}')\n",
    "print('-'*60)\n",
    "print(f'New tensor: \\n{y_reshaped.squeeze()}\\nNew Shape: {y_reshaped.squeeze().shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze\n",
    "<a href='https://pytorch.org/docs/stable/generated/torch.unsqueeze.html'>TORCH.UNSQUEEZE Documentation</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: \n",
      "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous Shape: torch.Size([9])\n",
      "------------------------------------------------------------\n",
      "For dim 0 , New tensor: \n",
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New Shape: torch.Size([1, 9])\n",
      "------------------------------------------------------------\n",
      "For dim 1, New tensor: \n",
      "tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New Shape: torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() adds a single dimension to a target tensot at a specific dimension (dim)\n",
    "y_squeeze = y_reshaped.squeeze()\n",
    "print(f'Previous tensor: \\n{y_squeeze}\\nPrevious Shape: {y_squeeze.shape}')\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "y_unsqueezed = y_squeeze.unsqueeze(dim=0)\n",
    "print(f'For dim 0 , New tensor: \\n{y_unsqueezed}\\nNew Shape: {y_unsqueezed.shape}')\n",
    "print('-'*60)\n",
    "\n",
    "y_unsqueezed = y_squeeze.unsqueeze(dim=1)\n",
    "print(f'For dim 1, New tensor: \\n{y_unsqueezed}\\nNew Shape: {y_unsqueezed.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute\n",
    "<a href='https://pytorch.org/docs/stable/generated/torch.permute.html'>TORCH.PERMUTE Documentation</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original tensor: torch.Size([223, 224, 3])\n",
      "Shape of permuted tensor: torch.Size([3, 223, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(223,224,3)     # (height, width, color-channels)-----axis:(0, 1, 2)\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1)    # (color-channels, height, width)-----axis:(2, 0, 1)\n",
    "\n",
    "print(f'Shape of original tensor: {x_original.shape}')\n",
    "print(f'Shape of permuted tensor: {x_permuted.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8070), tensor(0.8070))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(727.), tensor(727.))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 727\n",
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
